---
title: "Rule Trends"
author: "Adam Ribaudo"
date: "3/28/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(arules)
library(tidyverse)
library(data.table)
library(readxl)
library(knitr)

```

# Load data

```{r dataprep}

df <- read_excel("..\\data\\online_retail_II.xlsx") %>%
  rename(InvoiceNo = Invoice, UnitPrice = Price, CustomerID = `Customer ID`) %>%
  mutate(isRefund = grepl("C", InvoiceNo) | Quantity < 0) %>%
  # Convert datetime to date
  mutate(InvoiceDate = as.Date(InvoiceDate, format = "%m/%d/%Y %H:%M")) %>%
  # Extract month
  mutate(InvoiceYearMonth = paste0(year(InvoiceDate),month(InvoiceDate))) %>%
  # Consider 2010 data only
  filter(grepl("2010",InvoiceYearMonth))

```

# Generate transactions

```{r message=FALSE, warning=FALSE}
item_col <- "Description"
transaction_col <- "InvoiceNo"
time_col <- "InvoiceYearMonth"

# Break dataframe up into months and generate list of transaction tables for each month
get_transactions <- function(x){
  as(split(as.data.frame(x)[,item_col],as.data.frame(x)[,transaction_col]), "transactions")
}

transactions_union <- get_transactions(df)
# Transactions by time period
transactions <- lapply(split(df,f=df[time_col]),get_transactions)
time_periods <- length(transactions)

```

# Explore minsupport values

```{r message=FALSE, warning=FALSE}
# Explore supports across all time partitions
supports <- c(.02,.03,.04,.05,.06,.07,.08,.09)
global_support_df <- data.frame(support = supports)
global_support_df$frequent_items <- as.vector(sapply(supports,function(x)length(eclat(transactions_union, parameter = list(supp = x, minlen=1), control=list(verbose=F)))))

ggplot(global_support_df) + geom_col(aes(x=factor(support),y=frequent_items))

```

```{r message=FALSE, warning=FALSE}
# Explore supports across each individual time partition
num_supports <- length(supports)
itemset_df <- expand.grid(supports, names(transactions)) %>% rename(support = 1, time_partition = 2)
itemset_df$frequent_items <- apply(itemset_df, 1, FUN=function(x) length(eclat(transactions[[x[2]]], parameter = list(supp = as.numeric(x[[1]]), minlen=1), control = list(verbose=F))))

ggplot(itemset_df) + geom_col(aes(x=factor(support),y=frequent_items,fill=time_partition), position="dodge")

```

# Determine rules of interest

Rules must meet minsup and minconf across at least 1 time partition AND meet minsup and minconf across the merged transaction set. 

```{r warning=FALSE}

minsup <- .02
minconf <- .35
critical_z <- -1.65 # equates to 95% confidence

# Collect rules from each individual time partition
rules <- lapply(transactions,function(transaction_set){
  apriori(transaction_set, parameter=list(support=minsup,confidence=minconf), control=list(verbose=F))
          })
# Union rules and evaluate support & confidence for these rules against the entire time period
union_rules <- rules[[1]]
for(x in rules[2:length(rules)]){
  union_rules <- arules::union(union_rules,x)
}

measures_union_df <- as.data.frame(interestMeasure(union_rules, measure=c("support","confidence"),transactions=transactions_union,reuse=F))
measures_union_df$label <- labels(union_rules)
measures_union_df <- measures_union_df %>% filter(support > minsup,confidence > minconf)

kable(measures_union_df %>% rename(rule = label))

```

# Find semi-stable and stable rules

Stable rules are discovered by first finding "Semi-stable" rules. These are rules that meet the minsup and minconf criteria in a statistically significant way. 

Stable rules are those that meet the "semi stable" criteria and also show signiicant homogeneity in support and confidence across time periods via a chi squared test. 

## Semi-stable

```{r message=FALSE, warning=FALSE}
# evaluate support & confidence for these rules against all individual time periods
measures <- lapply(transactions,function(x){
  interestMeasure(union_rules, measure=c("support","confidence","count","coverage"),transactions=x,reuse=F) %>% 
    mutate(antecedent_count = coverage * length(x))
  })
measures_df <- as.data.frame(rbindlist(measures,fill=T,idcol=T)) 
measures_df$label <- rep(labels(union_rules),length(transactions))
# Filter down to rules that exist as valid rules in the global set
measures_df <- measures_df %>% inner_join(measures_union_df %>% select(label)) %>%
# Include count of (B|~A) for chi squared test
mutate(inverse_count = antecedent_count - count) %>% filter(support > 0,confidence > 0)

test_statistic <- function(p_hat,min_val,n){
  (p_hat - min_val) / (sqrt((min_val*(1-min_val))/n))
}

semi_stable_df <- measures_df %>% rename(rule_count = count) %>%
  #filter(support > global_minsup,confidence>global_minconf) %>%
  mutate(conf_test_statistic = test_statistic(confidence,minconf,antecedent_count)) %>%
  mutate(supp_test_statistic = test_statistic(support,minsup,antecedent_count)) %>%
  # Remove any entries that are significantly below min_conf
  filter(conf_test_statistic > critical_z, supp_test_statistic > critical_z) %>%
  # Count how many time periods the rule is still associated with
  group_by(label) %>% tally() %>% filter(n >= time_periods)

kable(semi_stable_df %>% rename(rule=label))
```

## Stable

```{r message=FALSE, warning=FALSE}
# Evaluate stable rules:
labels_split <- split(measures_df %>% select(label,count, inverse_count),f=measures_df$label)
p_values_df <- rownames_to_column(as.data.frame(sapply(labels_split,function(x){chisq.test(x %>% select(-label))$p.value}))) %>% rename(label = rowname,pvalue = 2)

# Stable rules must also be semi-stable rules. Drop rules that reject the null hypothesis that the observations are homogenius
stable_df <- semi_stable_df %>% inner_join(p_values_df) %>% filter(pvalue > .05) %>% inner_join(measures_union_df) %>% select(-n,-pvalue)

kable(stable_df %>% rename(rule=label))
```
